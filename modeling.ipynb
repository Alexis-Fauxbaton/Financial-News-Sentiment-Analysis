{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, FastText\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from data_processing import read_data\n",
    "import torch\n",
    "from model import *\n",
    "from utils import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 250\n",
    "device='cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Word2Vec model on corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stocks making the biggest moves before the bel...</td>\n",
       "      <td>https://www.cnbc.com/2023/03/28/stocks-making-...</td>\n",
       "      <td>chinese technology stocks such as alibaba and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Be very vigilant': Bank of England chief says...</td>\n",
       "      <td>https://www.cnbc.com/2023/03/28/bank-of-englan...</td>\n",
       "      <td>andrew bailey, governor of the bank of england...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is not another banking crisis, analysts s...</td>\n",
       "      <td>https://www.cnbc.com/2023/03/28/this-is-not-an...</td>\n",
       "      <td>the collapse of u.s.-based silicon valley bank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private equity deals in Asia plunged 44% in 20...</td>\n",
       "      <td>https://www.cnbc.com/2023/03/28/private-equity...</td>\n",
       "      <td>asia-pacific's private equity market plummeted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stocks making the biggest midday moves: Coinba...</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/stocks-making-...</td>\n",
       "      <td>check out the companies making the biggest mov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   \n",
       "0  Stocks making the biggest moves before the bel...  \\\n",
       "1  'Be very vigilant': Bank of England chief says...   \n",
       "2  This is not another banking crisis, analysts s...   \n",
       "3  Private equity deals in Asia plunged 44% in 20...   \n",
       "4  Stocks making the biggest midday moves: Coinba...   \n",
       "\n",
       "                                                 URL   \n",
       "0  https://www.cnbc.com/2023/03/28/stocks-making-...  \\\n",
       "1  https://www.cnbc.com/2023/03/28/bank-of-englan...   \n",
       "2  https://www.cnbc.com/2023/03/28/this-is-not-an...   \n",
       "3  https://www.cnbc.com/2023/03/28/private-equity...   \n",
       "4  https://www.cnbc.com/2023/03/27/stocks-making-...   \n",
       "\n",
       "                                             Content  \n",
       "0  chinese technology stocks such as alibaba and ...  \n",
       "1  andrew bailey, governor of the bank of england...  \n",
       "2  the collapse of u.s.-based silicon valley bank...  \n",
       "3  asia-pacific's private equity market plummeted...  \n",
       "4  check out the companies making the biggest mov...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv(\"corpus.csv\", sep='@', index_col=0)\n",
    "corpus = corpus.loc[corpus['Content'] != '']\n",
    "corpus.dropna(subset=['Content'], axis=0, inplace=True)\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding training data in the corpus\n",
    "training_data = read_data(\"FinancialPhraseBank/Sentences_50Agree.txt\")\n",
    "training_data['News'] = training_data['News'].str.lower()\n",
    "training_data['News'] = training_data['News'].str.replace('\\n', '')\n",
    "training_data.dropna(subset=['News'], axis=0, inplace=True)\n",
    "training_data = training_data.loc[training_data['News'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = [word_tokenize(row[-1]) for _, row in corpus.iterrows()] + [word_tokenize(row[0]) for _, row in training_data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_content = [word_tokenize(row[0]) for _, row in training_data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(sentence) for sentence in training_content]) # Max headline token length, going to need to pad according to this number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(sentences=content, vector_size=embedding_size, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('increased.some', 0.9702471494674683),\n",
       " ('increase.as', 0.9593074321746826),\n",
       " ('incredibly', 0.9375899434089661),\n",
       " ('increases', 0.936568558216095),\n",
       " ('increased', 0.9365633726119995),\n",
       " ('increasingly', 0.9178104996681213),\n",
       " ('grease', 0.9151845574378967),\n",
       " ('outcomes.increased', 0.9145744442939758),\n",
       " ('ratify', 0.9096012115478516),\n",
       " ('raivv', 0.9074144959449768)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = model.wv.most_similar('increase', topn=10)\n",
    "sims"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Train/Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_data(\"FinancialPhraseBank/Sentences_50Agree.txt\")\n",
    "sentiment_dataset = NewsDataset(dataset, model.wv, embedding_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>according to gran , the company has no plans t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>technopolis plans to develop in stages an area...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the international electronic industry company ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with the new production plant the company woul...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>according to the company 's updated strategy f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>london marketwatch -- share prices ended lower...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>operating profit fell to eur 35.4 mn from eur ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>net sales of the paper segment decreased to eu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>sales in finland decreased by 10.5 % in januar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   News  Sentiment\n",
       "0     according to gran , the company has no plans t...          1\n",
       "1     technopolis plans to develop in stages an area...          1\n",
       "2     the international electronic industry company ...          0\n",
       "3     with the new production plant the company woul...          2\n",
       "4     according to the company 's updated strategy f...          2\n",
       "...                                                 ...        ...\n",
       "4841  london marketwatch -- share prices ended lower...          0\n",
       "4842  rinkuskiai 's beer sales fell by 6.5 per cent ...          1\n",
       "4843  operating profit fell to eur 35.4 mn from eur ...          0\n",
       "4844  net sales of the paper segment decreased to eu...          0\n",
       "4845  sales in finland decreased by 10.5 % in januar...          0\n",
       "\n",
       "[4846 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(sentiment_dataset, [round(0.7*len(sentiment_dataset)), round(0.3*len(sentiment_dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sentiment\n",
       " 1    2019\n",
       " 2     960\n",
       " 0     413\n",
       " Name: count, dtype: int64,\n",
       " Sentiment\n",
       " 1    0.591472\n",
       " 2    0.277166\n",
       " 0    0.131362\n",
       " Name: count, dtype: float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[train_set.indices, 'Sentiment'].value_counts(), dataset.loc[val_set.indices, 'Sentiment'].value_counts() / dataset.loc[val_set.indices, 'Sentiment'].shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = embedding_size\n",
    "batch_size = 64\n",
    "num_layers = 1\n",
    "hidden_size = 500\n",
    "lstm_model = LSTMModel(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexis\\Documents\\Projets\\Financial-News-Sentiment-Analysis\\model.py:37: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  x = torch.FloatTensor(sentence).reshape((n, self.embedding_size))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 -- [3392/3392 (100.0%)]\tLoss: 0.5450158057347784\tAccuracy: 0.588\tTime taken: 88.640625\tValidation Loss: 0.5256201028823853 || Validation Accuracy: 0.621\n",
      "Epoch: 2/30 -- [3392/3392 (100.0%)]\tLoss: 0.5097310329383274\tAccuracy: 0.632\tTime taken: 86.921875\tValidation Loss: 0.513260543346405 || Validation Accuracy: 0.641\n",
      "Epoch: 3/30 -- [3392/3392 (100.0%)]\tLoss: 0.49624588017193777\tAccuracy: 0.637\tTime taken: 87.59375\tValidation Loss: 0.49810242652893066 || Validation Accuracy: 0.638\n",
      "Epoch: 4/30 -- [3392/3392 (100.0%)]\tLoss: 0.47876273573569533\tAccuracy: 0.654\tTime taken: 87.1875\tValidation Loss: 0.5065155625343323 || Validation Accuracy: 0.653\n",
      "Epoch: 5/30 -- [3392/3392 (100.0%)]\tLoss: 0.4667603441004483\tAccuracy: 0.659\tTime taken: 98.03125\tValidation Loss: 0.48722904920578003 || Validation Accuracy: 0.657\n",
      "Epoch: 6/30 -- [3392/3392 (100.0%)]\tLoss: 0.46335391953306376\tAccuracy: 0.666\tTime taken: 91.59375\tValidation Loss: 0.4929247796535492 || Validation Accuracy: 0.664\n",
      "Epoch: 7/30 -- [3392/3392 (100.0%)]\tLoss: 0.4501104995889484\tAccuracy: 0.672\tTime taken: 91.8125\tValidation Loss: 0.497626394033432 || Validation Accuracy: 0.648\n",
      "Epoch: 8/30 -- [3392/3392 (100.0%)]\tLoss: 0.44154885298800917\tAccuracy: 0.672\tTime taken: 91.546875\tValidation Loss: 0.4787460267543793 || Validation Accuracy: 0.667\n",
      "Epoch: 9/30 -- [3392/3392 (100.0%)]\tLoss: 0.4265644786492834\tAccuracy: 0.689\tTime taken: 91.140625\tValidation Loss: 0.4855367839336395 || Validation Accuracy: 0.649\n",
      "Epoch: 10/30 -- [3392/3392 (100.0%)]\tLoss: 0.42185696003572\tAccuracy: 0.688\tTime taken: 91.078125\tValidation Loss: 0.4799489676952362 || Validation Accuracy: 0.662\n",
      "Epoch: 11/30 -- [3392/3392 (100.0%)]\tLoss: 0.4128099814900812\tAccuracy: 0.697\tTime taken: 89.4375\tValidation Loss: 0.48690396547317505 || Validation Accuracy: 0.666\n",
      "Epoch: 12/30 -- [3392/3392 (100.0%)]\tLoss: 0.4064915095860103\tAccuracy: 0.693\tTime taken: 90.125\tValidation Loss: 0.48607975244522095 || Validation Accuracy: 0.669\n",
      "Epoch: 13/30 -- [3392/3392 (100.0%)]\tLoss: 0.40479370951652527\tAccuracy: 0.709\tTime taken: 89.1875\tValidation Loss: 0.5145604014396667 || Validation Accuracy: 0.666\n",
      "Epoch: 14/30 -- [3392/3392 (100.0%)]\tLoss: 0.40048695341596063\tAccuracy: 0.705\tTime taken: 90.265625\tValidation Loss: 0.4899015426635742 || Validation Accuracy: 0.660\n",
      "Epoch: 15/30 -- [3392/3392 (100.0%)]\tLoss: 0.37887172091682003\tAccuracy: 0.725\tTime taken: 91.109375\tValidation Loss: 0.5410900712013245 || Validation Accuracy: 0.668\n",
      "Epoch: 16/30 -- [3392/3392 (100.0%)]\tLoss: 0.38355098580414393\tAccuracy: 0.721\tTime taken: 92.53125\tValidation Loss: 0.5419500470161438 || Validation Accuracy: 0.665\n",
      "Epoch: 17/30 -- [3392/3392 (100.0%)]\tLoss: 0.3781532127902193\tAccuracy: 0.727\tTime taken: 93.96875\tValidation Loss: 0.5452059507369995 || Validation Accuracy: 0.671\n",
      "Epoch: 18/30 -- [3392/3392 (100.0%)]\tLoss: 0.3635732132308888\tAccuracy: 0.740\tTime taken: 97.484375\tValidation Loss: 0.5266035199165344 || Validation Accuracy: 0.632\n",
      "Epoch: 19/30 -- [3392/3392 (100.0%)]\tLoss: 0.357504332965275\tAccuracy: 0.731\tTime taken: 98.546875\tValidation Loss: 0.5141146183013916 || Validation Accuracy: 0.665\n",
      "Epoch: 20/30 -- [3392/3392 (100.0%)]\tLoss: 0.3594315597471201\tAccuracy: 0.736\tTime taken: 99.0625\tValidation Loss: 0.6106123924255371 || Validation Accuracy: 0.652\n",
      "Epoch: 21/30 -- [3392/3392 (100.0%)]\tLoss: 0.34081914852250295\tAccuracy: 0.752\tTime taken: 103.15625\tValidation Loss: 0.5741338133811951 || Validation Accuracy: 0.649\n",
      "Epoch: 22/30 -- [3392/3392 (100.0%)]\tLoss: 0.35023650217731045\tAccuracy: 0.743\tTime taken: 108.328125\tValidation Loss: 0.6482006907463074 || Validation Accuracy: 0.565\n",
      "Epoch: 23/30 -- [3392/3392 (100.0%)]\tLoss: 0.363102691353492\tAccuracy: 0.732\tTime taken: 105.859375\tValidation Loss: 0.5657860040664673 || Validation Accuracy: 0.655\n",
      "Epoch: 24/30 -- [3392/3392 (100.0%)]\tLoss: 0.3417814573589361\tAccuracy: 0.754\tTime taken: 109.6875\tValidation Loss: 0.552251935005188 || Validation Accuracy: 0.651\n",
      "Epoch: 25/30 -- [3392/3392 (100.0%)]\tLoss: 0.32715759693451646\tAccuracy: 0.765\tTime taken: 115.3125\tValidation Loss: 0.5858401656150818 || Validation Accuracy: 0.651\n",
      "Epoch: 26/30 -- [3392/3392 (100.0%)]\tLoss: 0.32970263513754\tAccuracy: 0.763\tTime taken: 118.0\tValidation Loss: 0.5361294746398926 || Validation Accuracy: 0.640\n",
      "Epoch: 27/30 -- [3392/3392 (100.0%)]\tLoss: 0.31801445725953803\tAccuracy: 0.772\tTime taken: 119.796875\tValidation Loss: 0.5839241743087769 || Validation Accuracy: 0.619\n",
      "Epoch: 28/30 -- [3392/3392 (100.0%)]\tLoss: 0.31515604707429995\tAccuracy: 0.773\tTime taken: 121.0\tValidation Loss: 0.5778267979621887 || Validation Accuracy: 0.646\n",
      "Epoch: 29/30 -- [3392/3392 (100.0%)]\tLoss: 0.2954532765554932\tAccuracy: 0.787\tTime taken: 126.296875\tValidation Loss: 0.611295223236084 || Validation Accuracy: 0.642\n",
      "Epoch: 30/30 -- [3392/3392 (100.0%)]\tLoss: 0.3019534447845423\tAccuracy: 0.782\tTime taken: 131.78125\tValidation Loss: 0.621046245098114 || Validation Accuracy: 0.655\n",
      "Best accuracy : 0.671251719394773 || Best confusion matrix : \n",
      " [[  0.  90. 101.]\n",
      " [  0. 792.  68.]\n",
      " [  0. 219. 184.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.5450158057347784,\n",
       "  0.5097310329383274,\n",
       "  0.49624588017193777,\n",
       "  0.47876273573569533,\n",
       "  0.4667603441004483,\n",
       "  0.46335391953306376,\n",
       "  0.4501104995889484,\n",
       "  0.44154885298800917,\n",
       "  0.4265644786492834,\n",
       "  0.42185696003572,\n",
       "  0.4128099814900812,\n",
       "  0.4064915095860103,\n",
       "  0.40479370951652527,\n",
       "  0.40048695341596063,\n",
       "  0.37887172091682003,\n",
       "  0.38355098580414393,\n",
       "  0.3781532127902193,\n",
       "  0.3635732132308888,\n",
       "  0.357504332965275,\n",
       "  0.3594315597471201,\n",
       "  0.34081914852250295,\n",
       "  0.35023650217731045,\n",
       "  0.363102691353492,\n",
       "  0.3417814573589361,\n",
       "  0.32715759693451646,\n",
       "  0.32970263513754,\n",
       "  0.31801445725953803,\n",
       "  0.31515604707429995,\n",
       "  0.2954532765554932,\n",
       "  0.3019534447845423],\n",
       " [0.5881485849056604,\n",
       "  0.6317806603773585,\n",
       "  0.6367924528301887,\n",
       "  0.6535966981132075,\n",
       "  0.6586084905660378,\n",
       "  0.6659787735849056,\n",
       "  0.6715801886792453,\n",
       "  0.6724646226415094,\n",
       "  0.6886792452830188,\n",
       "  0.6875,\n",
       "  0.6969339622641509,\n",
       "  0.6931014150943396,\n",
       "  0.7090212264150944,\n",
       "  0.7045990566037735,\n",
       "  0.7252358490566038,\n",
       "  0.7211084905660378,\n",
       "  0.7267099056603774,\n",
       "  0.7399764150943396,\n",
       "  0.7308372641509434,\n",
       "  0.7355542452830188,\n",
       "  0.7523584905660378,\n",
       "  0.7429245283018868,\n",
       "  0.7317216981132075,\n",
       "  0.7535377358490566,\n",
       "  0.7653301886792453,\n",
       "  0.7632665094339622,\n",
       "  0.7721108490566038,\n",
       "  0.7727004716981132,\n",
       "  0.7871462264150944,\n",
       "  0.7821344339622641],\n",
       " [tensor(0.5256),\n",
       "  tensor(0.5133),\n",
       "  tensor(0.4981),\n",
       "  tensor(0.5065),\n",
       "  tensor(0.4872),\n",
       "  tensor(0.4929),\n",
       "  tensor(0.4976),\n",
       "  tensor(0.4787),\n",
       "  tensor(0.4855),\n",
       "  tensor(0.4799),\n",
       "  tensor(0.4869),\n",
       "  tensor(0.4861),\n",
       "  tensor(0.5146),\n",
       "  tensor(0.4899),\n",
       "  tensor(0.5411),\n",
       "  tensor(0.5420),\n",
       "  tensor(0.5452),\n",
       "  tensor(0.5266),\n",
       "  tensor(0.5141),\n",
       "  tensor(0.6106),\n",
       "  tensor(0.5741),\n",
       "  tensor(0.6482),\n",
       "  tensor(0.5658),\n",
       "  tensor(0.5523),\n",
       "  tensor(0.5858),\n",
       "  tensor(0.5361),\n",
       "  tensor(0.5839),\n",
       "  tensor(0.5778),\n",
       "  tensor(0.6113),\n",
       "  tensor(0.6210)],\n",
       " [0.6210453920220083,\n",
       "  0.640990371389271,\n",
       "  0.6382393397524071,\n",
       "  0.6526822558459422,\n",
       "  0.6568088033012379,\n",
       "  0.6643741403026134,\n",
       "  0.6478679504814305,\n",
       "  0.6671251719394773,\n",
       "  0.6492434662998624,\n",
       "  0.6623108665749656,\n",
       "  0.6657496561210454,\n",
       "  0.6691884456671252,\n",
       "  0.6664374140302614,\n",
       "  0.6595598349381018,\n",
       "  0.6678129298486932,\n",
       "  0.6650618982118295,\n",
       "  0.671251719394773,\n",
       "  0.6320495185694636,\n",
       "  0.6650618982118295,\n",
       "  0.6519944979367263,\n",
       "  0.6485557083906465,\n",
       "  0.5653370013755158,\n",
       "  0.655433287482806,\n",
       "  0.6513067400275103,\n",
       "  0.6513067400275103,\n",
       "  0.640302613480055,\n",
       "  0.6189821182943603,\n",
       "  0.6464924346629987,\n",
       "  0.6416781292984869,\n",
       "  0.655433287482806],\n",
       " array([[  0.,  90., 101.],\n",
       "        [  0., 792.,  68.],\n",
       "        [  0., 219., 184.]]),\n",
       " 0.671251719394773)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lstm(lstm_model, train_set, val_set,  30, 0.01, batch_size, num_layers, hidden_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dogecoin', 'price', 'suddenly', 'rose', 'after', 'elon', 'musk', 'tweet']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[9.5867e-02, 4.7276e-01, 4.3138e-01],\n",
       "         [8.7565e-04, 6.4110e-01, 3.5802e-01],\n",
       "         [2.6831e-06, 7.9604e-01, 2.0396e-01],\n",
       "         [2.9390e-08, 9.9919e-01, 8.0943e-04],\n",
       "         [8.1049e-09, 9.9996e-01, 3.5048e-05],\n",
       "         [4.1709e-09, 1.0000e+00, 3.5744e-06],\n",
       "         [4.0630e-09, 1.0000e+00, 2.7370e-06],\n",
       "         [4.1289e-09, 1.0000e+00, 2.6553e-06],\n",
       "         [4.1714e-09, 1.0000e+00, 2.6428e-06],\n",
       "         [4.1922e-09, 1.0000e+00, 2.6509e-06],\n",
       "         [4.1942e-09, 1.0000e+00, 2.6599e-06],\n",
       "         [4.1842e-09, 1.0000e+00, 2.6680e-06],\n",
       "         [4.1677e-09, 1.0000e+00, 2.6754e-06],\n",
       "         [4.1482e-09, 1.0000e+00, 2.6827e-06],\n",
       "         [4.1272e-09, 1.0000e+00, 2.6897e-06],\n",
       "         [4.1057e-09, 1.0000e+00, 2.6967e-06],\n",
       "         [4.0843e-09, 1.0000e+00, 2.7036e-06],\n",
       "         [4.0630e-09, 1.0000e+00, 2.7102e-06],\n",
       "         [4.0422e-09, 1.0000e+00, 2.7165e-06],\n",
       "         [4.0218e-09, 1.0000e+00, 2.7226e-06],\n",
       "         [4.0018e-09, 1.0000e+00, 2.7284e-06],\n",
       "         [3.9823e-09, 1.0000e+00, 2.7339e-06],\n",
       "         [3.9633e-09, 1.0000e+00, 2.7390e-06],\n",
       "         [3.9448e-09, 1.0000e+00, 2.7438e-06],\n",
       "         [3.9267e-09, 1.0000e+00, 2.7483e-06],\n",
       "         [3.9092e-09, 1.0000e+00, 2.7524e-06],\n",
       "         [3.8921e-09, 1.0000e+00, 2.7563e-06],\n",
       "         [3.8755e-09, 1.0000e+00, 2.7598e-06],\n",
       "         [3.8594e-09, 1.0000e+00, 2.7631e-06],\n",
       "         [3.8437e-09, 1.0000e+00, 2.7662e-06],\n",
       "         [3.8285e-09, 1.0000e+00, 2.7689e-06],\n",
       "         [3.8137e-09, 1.0000e+00, 2.7714e-06],\n",
       "         [3.7994e-09, 1.0000e+00, 2.7737e-06],\n",
       "         [3.7855e-09, 1.0000e+00, 2.7758e-06],\n",
       "         [3.7721e-09, 1.0000e+00, 2.7776e-06],\n",
       "         [3.7590e-09, 1.0000e+00, 2.7793e-06],\n",
       "         [3.7463e-09, 1.0000e+00, 2.7808e-06],\n",
       "         [3.7341e-09, 1.0000e+00, 2.7820e-06],\n",
       "         [3.7222e-09, 1.0000e+00, 2.7831e-06],\n",
       "         [3.7107e-09, 1.0000e+00, 2.7841e-06],\n",
       "         [3.6995e-09, 1.0000e+00, 2.7849e-06],\n",
       "         [3.6887e-09, 1.0000e+00, 2.7855e-06],\n",
       "         [3.6782e-09, 1.0000e+00, 2.7860e-06],\n",
       "         [3.6681e-09, 1.0000e+00, 2.7864e-06],\n",
       "         [3.6583e-09, 1.0000e+00, 2.7866e-06],\n",
       "         [3.6488e-09, 1.0000e+00, 2.7867e-06],\n",
       "         [3.6396e-09, 1.0000e+00, 2.7867e-06],\n",
       "         [3.6307e-09, 1.0000e+00, 2.7866e-06],\n",
       "         [3.6221e-09, 1.0000e+00, 2.7864e-06],\n",
       "         [3.6137e-09, 1.0000e+00, 2.7861e-06],\n",
       "         [3.6056e-09, 1.0000e+00, 2.7857e-06],\n",
       "         [3.5978e-09, 1.0000e+00, 2.7852e-06],\n",
       "         [3.5903e-09, 1.0000e+00, 2.7846e-06],\n",
       "         [3.5830e-09, 1.0000e+00, 2.7839e-06],\n",
       "         [3.5759e-09, 1.0000e+00, 2.7832e-06],\n",
       "         [3.5691e-09, 1.0000e+00, 2.7824e-06],\n",
       "         [3.5625e-09, 1.0000e+00, 2.7815e-06],\n",
       "         [3.5561e-09, 1.0000e+00, 2.7806e-06],\n",
       "         [3.5499e-09, 1.0000e+00, 2.7796e-06],\n",
       "         [3.5439e-09, 1.0000e+00, 2.7786e-06],\n",
       "         [3.5381e-09, 1.0000e+00, 2.7775e-06],\n",
       "         [3.5325e-09, 1.0000e+00, 2.7763e-06],\n",
       "         [3.5271e-09, 1.0000e+00, 2.7751e-06],\n",
       "         [3.5219e-09, 1.0000e+00, 2.7739e-06],\n",
       "         [3.5168e-09, 1.0000e+00, 2.7726e-06],\n",
       "         [3.5119e-09, 1.0000e+00, 2.7712e-06],\n",
       "         [3.5072e-09, 1.0000e+00, 2.7699e-06],\n",
       "         [3.5026e-09, 1.0000e+00, 2.7684e-06],\n",
       "         [3.4982e-09, 1.0000e+00, 2.7670e-06],\n",
       "         [3.4939e-09, 1.0000e+00, 2.7655e-06],\n",
       "         [3.4897e-09, 1.0000e+00, 2.7640e-06],\n",
       "         [3.4857e-09, 1.0000e+00, 2.7624e-06],\n",
       "         [3.4818e-09, 1.0000e+00, 2.7608e-06],\n",
       "         [1.0090e-03, 9.8693e-01, 1.2064e-02],\n",
       "         [3.6907e-05, 9.9985e-01, 1.1077e-04],\n",
       "         [6.3349e-03, 9.8886e-01, 4.8007e-03],\n",
       "         [5.5822e-03, 9.9251e-01, 1.9066e-03],\n",
       "         [7.8279e-01, 2.9548e-02, 1.8767e-01],\n",
       "         [4.2083e-06, 9.9468e-01, 5.3153e-03],\n",
       "         [4.8331e-02, 8.8576e-02, 8.6309e-01],\n",
       "         [3.0725e-01, 7.8941e-02, 6.1381e-01]], grad_fn=<SoftmaxBackward0>),\n",
       " (tensor([[ 5.4236e-02,  4.8877e-04,  2.3429e-04, -1.5807e-07,  6.9993e-06,\n",
       "           -6.6243e-01, -7.6058e-01, -3.0519e-02, -3.8394e-06,  2.9527e-01,\n",
       "           -1.2434e-06,  2.4046e-01,  3.0914e-04,  9.5340e-05, -1.0397e-04,\n",
       "            1.3856e-06, -4.8198e-07,  8.6803e-03,  8.7068e-09, -4.1778e-05,\n",
       "           -1.2446e-11, -6.9591e-01,  1.2393e-03,  1.7041e-03, -8.6870e-04,\n",
       "            7.4172e-05, -4.7820e-06, -1.0437e-03,  1.3514e-03,  7.6057e-03,\n",
       "            9.6220e-01,  1.8647e-02,  4.9483e-01, -2.0878e-04,  3.6020e-03,\n",
       "           -6.1132e-01, -4.3379e-06,  9.4137e-05,  1.0089e-06,  3.5605e-06,\n",
       "           -1.1171e-05, -5.0997e-05,  7.8017e-07,  5.4140e-08, -7.5948e-01,\n",
       "            3.3536e-04, -2.4256e-07, -4.1356e-01, -1.8151e-01, -7.0541e-06,\n",
       "            7.6727e-06, -3.1376e-02,  8.1538e-03,  4.1345e-04,  2.2765e-04,\n",
       "            1.3235e-03,  7.6050e-01,  1.0124e-09,  5.5789e-02,  1.2837e-06,\n",
       "           -1.8195e-05,  6.3760e-01, -7.5738e-01,  4.4302e-05, -1.6605e-05,\n",
       "           -1.3338e-05,  4.2941e-03, -1.3620e-03,  3.9944e-01,  9.9326e-01,\n",
       "           -2.0415e-05,  7.0825e-03,  3.7704e-05,  3.1698e-05,  1.0507e-04,\n",
       "            3.4042e-04, -1.5355e-04, -8.0603e-06, -3.4877e-06, -1.5726e-05,\n",
       "            1.5400e-04, -5.0893e-03,  4.5105e-05, -5.4020e-07, -1.2542e-01,\n",
       "           -6.9556e-07, -9.7766e-01, -8.5009e-06,  2.4129e-04,  9.8360e-01,\n",
       "           -6.4112e-05, -9.7912e-07,  8.7652e-04,  1.5672e-03, -4.4611e-06,\n",
       "            6.0710e-02, -2.2840e-06,  9.8014e-01,  8.6441e-02, -9.8336e-04,\n",
       "            4.7010e-01,  9.6789e-06,  3.4805e-01, -2.5970e-06,  1.8250e-02,\n",
       "            7.8037e-06, -4.0564e-01, -7.3122e-05, -8.5069e-04,  7.3416e-01,\n",
       "            3.5491e-04, -8.7503e-04, -1.4091e-03,  6.7044e-06, -9.1030e-07,\n",
       "            4.1884e-04, -8.6053e-07, -7.6585e-06, -3.5680e-07, -9.1665e-06,\n",
       "            2.0737e-05,  7.2980e-01, -5.4792e-05, -4.6496e-04, -8.7124e-04,\n",
       "           -1.8307e-08,  1.7092e-10,  6.5564e-06,  9.8740e-07, -7.9042e-04,\n",
       "            1.4465e-03, -7.9090e-04,  2.6018e-05,  2.1652e-06, -5.0854e-01,\n",
       "            9.7445e-01, -1.8419e-06, -2.3622e-08,  5.5167e-01,  1.7455e-04,\n",
       "           -4.1782e-01,  2.1714e-03,  9.9721e-01, -2.2942e-04,  2.3512e-02,\n",
       "           -8.0894e-01,  7.6163e-05, -2.4350e-08, -2.7653e-03, -4.0473e-05,\n",
       "            1.7451e-05, -1.1158e-03,  1.0000e+00,  4.9927e-05,  1.9175e-04,\n",
       "            1.2962e-01, -8.8223e-05, -3.8792e-08, -9.7492e-06,  3.0305e-04,\n",
       "           -1.2467e-06, -3.2483e-05, -9.9999e-01, -5.3312e-06, -3.0312e-01,\n",
       "            8.5270e-07,  2.2884e-04,  1.0951e-03,  1.0824e-06,  2.8143e-06,\n",
       "            7.7969e-09,  3.2501e-07, -7.4764e-01,  1.8256e-05,  2.6792e-06,\n",
       "            1.3768e-10,  2.1089e-03,  3.3342e-07,  3.1428e-04, -9.7298e-02,\n",
       "           -3.4222e-05,  4.7478e-04,  3.5907e-04, -1.7952e-04,  9.9681e-06,\n",
       "            6.6710e-01, -6.5063e-02,  9.9997e-01, -7.9286e-05, -7.6444e-04,\n",
       "            4.6108e-05,  5.6239e-03,  1.8680e-02, -3.2266e-01,  1.6089e-04,\n",
       "           -1.4818e-05, -3.8599e-04, -7.4914e-02, -9.2117e-01, -9.4911e-06,\n",
       "           -3.2622e-03, -3.4555e-03,  2.3697e-03,  1.5499e-01, -3.6395e-05,\n",
       "            2.6290e-07, -4.2073e-02, -3.3674e-03, -9.7803e-09,  8.4227e-01,\n",
       "            1.4068e-07, -2.0397e-01,  3.6165e-01, -2.6684e-05, -4.0387e-05,\n",
       "            8.4476e-02, -2.4805e-04,  6.9121e-02,  1.0470e-03, -3.2940e-06,\n",
       "            6.1452e-01,  1.2594e-05, -1.4697e-06,  5.1865e-05,  1.0996e-05,\n",
       "           -6.6592e-02,  2.0970e-07, -8.3943e-05, -1.3515e-01,  6.0924e-05,\n",
       "           -1.7760e-05, -1.3079e-01,  5.0894e-01,  1.0863e-04,  4.2263e-03,\n",
       "           -2.2247e-03,  4.8784e-05, -6.8186e-01, -2.7586e-01,  3.0742e-01,\n",
       "           -8.8810e-05, -3.4316e-04,  1.4896e-03, -4.5388e-08, -5.9238e-03,\n",
       "           -1.0910e-02,  8.3208e-02, -2.3582e-04,  9.3873e-03, -6.9064e-02,\n",
       "           -9.9218e-01,  6.9077e-05, -2.4202e-06, -2.8486e-03,  2.5523e-06,\n",
       "            9.9982e-01,  2.4342e-04,  3.3461e-03,  6.1833e-06, -5.4299e-03,\n",
       "            1.2505e-08, -4.3256e-02,  4.8260e-06, -1.0099e-04, -7.3678e-01,\n",
       "           -5.1349e-04, -6.4783e-06, -8.1241e-04,  5.1335e-08,  8.0131e-03,\n",
       "            1.0327e-01, -9.9249e-02,  1.0197e-08,  1.3481e-04, -5.0406e-02,\n",
       "           -7.3719e-01,  2.1126e-05,  5.8169e-02,  8.1690e-01, -3.4208e-01,\n",
       "           -2.9331e-05, -1.6303e-09,  8.6610e-05,  7.8134e-04,  7.6313e-01,\n",
       "            2.2137e-05,  6.3357e-02,  8.8771e-04,  2.5016e-02, -1.2262e-08,\n",
       "           -8.0914e-04, -3.5111e-11,  9.0548e-04,  5.4422e-05, -1.6547e-05,\n",
       "           -5.9265e-06,  1.7436e-02, -2.7881e-06, -6.6484e-06,  9.2291e-01,\n",
       "           -1.6116e-07, -2.5484e-03,  2.5998e-04, -1.0000e+00,  1.6338e-03,\n",
       "            7.9354e-07, -5.4054e-05,  1.5382e-02, -1.0535e-05, -2.8427e-03,\n",
       "           -5.9123e-02, -6.4169e-05, -7.0505e-01, -1.5306e-06, -2.4716e-04,\n",
       "            1.1707e-01, -2.6566e-07, -9.3267e-07, -3.5656e-07,  4.2388e-07,\n",
       "           -8.0177e-01,  1.0830e-09,  7.0277e-07, -6.9482e-09, -2.7596e-05,\n",
       "            1.2882e-11,  9.9874e-01, -9.7618e-01, -4.9992e-01,  1.3079e-05,\n",
       "            1.3457e-04, -4.7986e-08,  5.3930e-04, -7.5485e-11, -2.0731e-04,\n",
       "           -6.6882e-02, -7.3288e-01,  2.4157e-04, -1.5712e-03, -6.4684e-04,\n",
       "            9.5345e-01, -3.2159e-06,  1.7520e-06, -1.9123e-01,  7.5244e-03,\n",
       "           -1.1622e-05, -1.9885e-01,  3.5085e-04,  1.7230e-03, -8.7375e-01,\n",
       "           -9.4063e-07,  9.4771e-03, -4.2024e-05,  1.7748e-02, -8.2457e-05,\n",
       "           -2.1588e-02, -1.6517e-05,  9.9928e-04,  2.6359e-02, -1.6198e-03,\n",
       "           -9.9972e-01, -1.0963e-04,  1.0211e-08, -1.6180e-06, -1.4238e-04,\n",
       "           -9.8754e-01, -1.9992e-10, -2.9605e-02, -9.5969e-04,  4.6076e-05,\n",
       "           -4.7486e-08, -1.0860e-07,  9.6602e-06, -2.9663e-02,  2.0152e-03,\n",
       "           -1.8215e-08, -1.5466e-05,  2.0217e-02, -8.4428e-06, -8.2011e-02,\n",
       "            1.7744e-01,  7.7048e-02, -9.5200e-05, -1.0275e-06, -7.4358e-01,\n",
       "           -5.3900e-04,  1.5961e-01,  4.8085e-05, -2.6308e-04,  7.0113e-03,\n",
       "            2.5635e-07,  9.9718e-01,  1.4528e-06,  7.4378e-01, -3.1744e-01,\n",
       "            1.3503e-04, -9.9899e-01, -1.1660e-01, -5.5084e-05, -3.7326e-06,\n",
       "            9.4334e-08, -4.1416e-04,  1.1029e-08,  8.9330e-08, -2.8475e-02,\n",
       "            2.3140e-03, -9.9999e-01,  3.8794e-04,  4.5012e-04, -1.2620e-03,\n",
       "           -9.9989e-01, -5.0481e-03, -5.7129e-09,  9.1911e-01,  4.5293e-04,\n",
       "            2.3011e-01, -1.4279e-02,  7.4226e-04, -9.0299e-01, -4.6381e-01,\n",
       "            1.9217e-01, -4.4083e-01,  1.3421e-04,  4.4035e-05,  3.0389e-04,\n",
       "           -7.1971e-03, -7.8869e-01,  1.5033e-06,  3.9572e-10,  5.4567e-04,\n",
       "            1.4273e-03, -5.7176e-05,  6.5497e-01,  2.6356e-04, -2.2501e-06,\n",
       "            4.2680e-09, -8.1357e-05,  2.0644e-07,  2.5367e-06, -1.8722e-02,\n",
       "           -8.5145e-07,  1.2616e-01,  1.9589e-01, -8.0129e-05, -1.8654e-05,\n",
       "           -7.0007e-05,  3.8788e-02, -7.3046e-06, -2.0921e-05,  1.8642e-03,\n",
       "            1.7079e-02,  8.2631e-06,  1.1276e-03,  5.0541e-03,  5.3243e-01,\n",
       "           -7.6078e-01,  4.0516e-07, -5.5602e-03, -5.4978e-02,  1.5441e-07,\n",
       "           -8.2743e-05, -2.1332e-07, -9.6224e-05,  4.3768e-04, -3.4820e-04,\n",
       "           -2.1684e-04,  3.6895e-06, -9.7541e-01, -1.1678e-06, -2.5251e-06,\n",
       "           -5.2444e-03,  1.4092e-05,  6.0416e-05,  7.8694e-02,  2.4682e-03,\n",
       "            2.5299e-06, -9.6085e-04, -5.7857e-01, -1.3708e-02,  3.9848e-07,\n",
       "            1.0802e-08,  6.4445e-08, -3.8689e-04, -1.7684e-08,  4.6046e-06,\n",
       "           -2.4301e-04,  4.4670e-08,  6.1677e-05,  1.0908e-01,  9.6053e-07,\n",
       "           -7.3377e-01, -1.2923e-02,  5.4781e-05, -2.0869e-05, -3.8970e-01,\n",
       "            4.4396e-04,  5.1312e-06,  8.4510e-03, -3.4557e-08, -1.9670e-05]],\n",
       "         grad_fn=<SqueezeBackward1>),\n",
       "  tensor([[ 9.9998e-01,  2.3907e-03,  1.8719e-02, -7.3528e-03,  2.4737e+01,\n",
       "           -7.9713e-01, -9.9946e-01, -3.0532e-02, -7.7389e-05,  9.9670e-01,\n",
       "           -4.4526e-06,  3.8886e+01,  1.2345e-02,  9.4741e-01, -7.8240e+01,\n",
       "            1.3893e-06, -1.1077e-01,  9.2858e-01,  5.5392e+01, -2.5360e-04,\n",
       "           -6.0508e-08, -1.4237e+00,  1.4802e-03,  1.6277e+00, -6.0514e-01,\n",
       "            1.1811e-04, -1.8645e+00, -6.2632e+01,  6.1711e+01,  5.2966e-02,\n",
       "            2.4730e+01,  9.9836e-01,  5.4245e-01, -2.8061e-02,  3.5466e+01,\n",
       "           -7.1243e-01, -3.4153e-03,  7.7602e+01,  4.6785e-04,  3.5605e-06,\n",
       "           -9.9213e-01, -7.5318e-01,  2.8047e+01,  8.7573e-08, -9.9675e-01,\n",
       "            9.9997e-01, -1.4659e-05, -4.4282e-01, -1.8354e-01, -6.7842e-01,\n",
       "            1.2011e-03, -3.1468e-02,  2.0788e-01,  2.0604e-01,  1.9492e-02,\n",
       "            5.9828e+01,  1.0019e+00,  1.7668e-06,  1.0350e+00,  3.0046e+00,\n",
       "           -3.4946e-03,  9.1617e-01, -9.9004e-01,  7.2027e-03, -5.2206e+01,\n",
       "           -1.8296e-01,  4.3455e-03, -1.3643e-03,  1.5985e+00,  2.9406e+00,\n",
       "           -2.3238e-02,  8.9473e-03,  7.0871e-01,  5.1462e+01,  1.0532e-04,\n",
       "            5.6986e-02, -4.2521e-01, -1.2184e-03, -3.4907e-06, -1.5783e-05,\n",
       "            2.3026e+00, -1.0049e-02,  6.7372e-03, -1.7706e-06, -7.3725e+01,\n",
       "           -1.0748e-04, -6.2230e+01, -8.5056e-06,  1.9626e+00,  4.3210e+01,\n",
       "           -4.0794e-01, -3.5365e-03,  3.8689e-01,  1.5672e-03, -9.9168e-01,\n",
       "            3.1280e+00, -4.0171e-02,  6.8162e+01,  1.5977e-01, -2.2184e+00,\n",
       "            5.2604e-01,  3.0181e-01,  3.6359e-01, -2.8926e-06,  1.8777e-01,\n",
       "            9.7759e-01, -8.7141e-01, -1.8914e-02, -9.7312e-03,  1.1573e+00,\n",
       "            1.2296e+00, -1.4730e-03, -1.3944e-02,  4.2932e-02, -9.1520e-01,\n",
       "            3.2795e+00, -8.0066e-04, -7.6622e-06, -4.4208e-05, -7.4846e-04,\n",
       "            2.6347e-01,  9.4134e-01, -5.4969e-05, -3.8529e-03, -1.4502e-03,\n",
       "           -6.7610e-04,  4.5747e-03,  7.0088e+01,  2.0672e-04, -3.7951e-02,\n",
       "            1.0004e+00, -2.7029e+00,  3.8387e+00,  6.8106e-02, -5.6083e-01,\n",
       "            6.7342e+01, -1.3254e-04, -6.0540e-05,  6.2637e-01,  7.3065e-02,\n",
       "           -7.4515e+01,  2.3893e+01,  6.0340e+01, -5.4339e-03,  2.5801e-01,\n",
       "           -1.1766e+00,  1.0705e-02, -2.4350e-08, -2.8043e-03, -4.0661e-05,\n",
       "            1.8490e+01, -4.4560e-01,  6.3871e+01,  6.4185e-01,  7.8911e-03,\n",
       "            6.5237e+01, -1.6210e-04, -4.4026e-07, -3.6703e+00,  2.7389e-01,\n",
       "           -1.1399e+00, -4.7993e-01, -6.4329e+00, -1.4062e-01, -8.2362e+00,\n",
       "            9.9555e-01,  3.2852e+00,  6.5275e-01,  1.0850e-06,  5.0946e+01,\n",
       "            3.9296e-01,  7.0999e-04, -9.6766e-01,  1.1592e-02,  3.6444e-01,\n",
       "            5.0932e-07,  1.6034e+00,  1.8923e-06,  1.0424e-03, -6.8435e+01,\n",
       "           -9.5239e-04,  4.7989e-04,  6.4295e-04, -6.2407e-02,  4.8796e-05,\n",
       "            8.6007e-01, -2.0968e+01,  1.6824e+01, -2.0835e-03, -7.6571e-04,\n",
       "            7.0454e+01,  9.3645e-01,  1.8832e-02, -8.9917e-01,  3.6491e-04,\n",
       "           -9.0724e-01, -2.2953e-03, -7.9042e-01, -1.6099e+00, -7.0003e-04,\n",
       "           -7.7816e-01, -9.5682e-01,  2.0820e-02,  1.5843e-01, -9.9261e-02,\n",
       "            1.4522e-04, -3.9184e+00, -1.1763e-01, -6.6606e+01,  1.2290e+00,\n",
       "            1.2375e-05, -2.0687e-01,  9.1465e-01, -4.7429e-03, -5.6682e-05,\n",
       "            7.4539e+01, -5.0957e-01,  6.9322e-02,  1.3891e+01, -2.6847e+00,\n",
       "            2.1135e+01,  1.7147e-05, -1.4702e-06,  6.8727e+01,  1.1467e-05,\n",
       "           -6.6750e-02,  5.5028e+00, -4.0354e-03, -4.5758e+00,  9.4974e-01,\n",
       "           -1.3375e-01, -2.4000e-01,  6.9070e+01,  3.7488e+01,  3.2402e-01,\n",
       "           -4.8244e-02,  5.4344e+01, -8.3258e-01, -9.4081e-01,  3.3363e-01,\n",
       "           -9.0265e-05, -5.2255e-01,  5.8420e+01, -5.1360e-04, -9.7800e-01,\n",
       "           -9.8840e-01,  7.5223e-01, -2.3589e-04,  5.7277e-01, -6.6794e+01,\n",
       "           -2.7770e+00,  8.9786e-02, -2.4266e-06, -3.6343e-01,  3.8490e-04,\n",
       "            5.6115e+00,  8.5722e-01,  1.2673e+00,  4.1281e+01, -1.3599e+00,\n",
       "            6.9292e+01, -1.2116e+00,  3.9463e-02, -9.1915e-01, -9.9996e-01,\n",
       "           -2.1949e-02, -4.4562e-04, -1.6141e-02,  3.8290e-04,  2.6884e-01,\n",
       "            1.0379e-01, -9.9579e-02,  8.1154e-04,  2.8285e-04, -5.0487e-02,\n",
       "           -9.4689e-01,  3.1340e-01,  5.8491e-02,  1.1475e+00, -9.6130e-01,\n",
       "           -6.1450e+01, -2.9780e-08,  5.1428e+01,  1.8071e-03,  1.0063e+00,\n",
       "            4.5722e-03,  1.5824e-01,  8.8779e-04,  3.2456e-01, -3.8700e-07,\n",
       "           -8.0915e-04, -2.7318e+00,  1.0707e+00,  1.5162e+00, -1.4144e+01,\n",
       "           -1.1189e+00,  7.1348e+01, -6.1724e+01, -9.7974e-04,  1.6153e+00,\n",
       "           -4.9703e-04, -8.5124e-01,  1.0372e+00, -6.8569e+01,  3.7499e-03,\n",
       "            3.5763e-03, -1.6082e+00,  2.2945e-02, -4.2394e+00, -2.8485e-03,\n",
       "           -5.9254e-02, -3.1293e-01, -8.7767e-01, -1.5306e-06, -1.3915e+00,\n",
       "            1.1881e-01, -3.2974e-04, -4.2041e-03, -7.0603e-01,  1.0407e-04,\n",
       "           -1.1183e+00,  1.2452e-04,  3.7017e-03, -4.8152e-06, -6.7129e-01,\n",
       "            2.0395e-07,  5.2669e+01, -3.7136e+00, -9.9966e-01,  9.7036e-01,\n",
       "            1.3337e-03, -3.7096e-01,  5.4691e-04, -8.3750e-08, -9.7942e-01,\n",
       "           -6.6990e-02, -1.0001e+00,  1.0059e+00, -9.9994e-01, -6.5789e-01,\n",
       "            1.9507e+00, -9.6528e-03,  1.5069e+00, -4.9079e-01,  1.0003e+00,\n",
       "           -1.1611e-02, -2.0178e-01,  2.4970e-02,  1.7261e-03, -1.3573e+00,\n",
       "           -6.0813e-03,  1.0662e+01, -4.4184e-01,  3.6407e-02, -2.3934e-03,\n",
       "           -2.1600e-02, -2.4745e-04,  6.5312e+01,  3.7459e-02, -9.3424e-01,\n",
       "           -3.4822e+01, -5.0655e-02,  2.5787e-04, -2.0349e-01, -1.0509e+00,\n",
       "           -2.7113e+01, -5.3905e-10, -2.9650e-02, -2.2929e-01,  1.3029e-03,\n",
       "           -7.4298e+01, -1.0566e-03,  7.1437e+01, -1.9380e-01,  2.0176e-03,\n",
       "           -6.4087e-01, -1.7586e-05,  1.0106e+00, -6.7522e-03, -8.2586e-02,\n",
       "            1.8890e-01,  2.7807e+00, -1.2327e-02, -2.1551e-01, -1.0003e+00,\n",
       "           -7.4073e+01,  1.6232e-01,  2.4328e-02, -4.4815e-02,  3.0912e+00,\n",
       "            1.9655e-04,  3.3123e+00,  4.8619e+00,  4.3718e+01, -3.3474e-01,\n",
       "            4.0779e-03, -2.9740e+01, -8.6211e-01, -5.9221e+01, -1.0003e+00,\n",
       "            7.5091e+01, -2.8208e+01,  2.7030e-05,  7.6052e-02, -5.1011e+01,\n",
       "            3.0326e+00, -6.7678e+01,  4.2098e-02,  7.0985e+01, -5.4773e-02,\n",
       "           -7.1424e+01, -5.0996e-03, -7.1427e+00,  2.8060e+00,  2.6400e-02,\n",
       "            2.3450e-01, -1.4600e-01,  1.7333e+01, -6.8187e+01, -9.5977e-01,\n",
       "            1.9915e-01, -1.0105e+00,  6.4403e+01,  7.4253e+00,  3.0393e-04,\n",
       "           -8.2235e-01, -1.0719e+00,  4.0511e+00,  5.5940e-08,  5.5490e-04,\n",
       "            2.8684e+01, -2.3280e-02,  7.8653e-01,  2.2490e+01, -2.2574e-06,\n",
       "            4.4077e-07, -9.9993e-01,  2.6568e-03,  3.5424e-05, -9.9949e-01,\n",
       "           -3.1447e-04,  1.3001e-01,  1.9846e-01, -1.7027e+00, -5.9704e+01,\n",
       "           -1.0382e-03,  1.3687e-01, -7.7157e-03, -1.4379e-02,  2.7190e-02,\n",
       "            1.7081e-02,  8.2631e-06,  1.5749e-01,  7.8435e-01,  5.9360e-01,\n",
       "           -9.9819e-01,  9.4496e-01, -1.1969e+01, -5.5037e-02,  2.7734e-02,\n",
       "           -2.6659e-04, -2.4701e-03, -4.6199e-01,  5.0235e-03, -1.3087e-03,\n",
       "           -2.6855e-03,  1.9047e-05, -2.1933e+00, -1.1730e-06, -2.5257e-06,\n",
       "           -5.6193e-03,  1.5219e-05,  5.4898e+01,  7.9058e-02,  8.9611e-03,\n",
       "            8.2452e-04, -2.8583e+00, -6.6104e-01, -8.9767e-02,  2.2282e-03,\n",
       "            2.5535e-04,  1.2199e-02, -2.7113e-02, -1.3537e-06,  2.3689e-05,\n",
       "           -9.9739e-01,  2.7413e-04,  6.6339e-01,  9.9866e-01,  1.8495e-01,\n",
       "           -9.9999e-01, -5.8332e+01,  4.1280e-03, -1.1293e-04, -7.1079e+01,\n",
       "            1.0882e-01,  1.3913e-01,  9.6388e-01, -2.7951e-04, -1.3758e-04]],\n",
       "         grad_fn=<SqueezeBackward1>)))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'Dogecoin price suddenly rose after Elon Musk tweet'\n",
    "test = test.lower()\n",
    "test = word_tokenize(test)\n",
    "n = len(test)\n",
    "print(test)\n",
    "test = [model.wv[token] for token in test]\n",
    "test = torch.Tensor(test)\n",
    "test = F.pad(test, (0, 0, max_length - n, 0), 'constant', 0)\n",
    "hidden = (torch.zeros(num_layers, hidden_size).to(device), torch.zeros(\n",
    "                num_layers, hidden_size).to(device))\n",
    "lstm_model(test, hidden)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e7f7ece2f4c3e30cc6971059714188e0a0cc944cd6cc9496d585856c2732f0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
