{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, FastText\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from data_processing import read_data\n",
    "import torch\n",
    "from model import *\n",
    "from utils import *\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_embedding_size = 250\n",
    "device='cuda'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pretrained FastText embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_path = './sogou_news.bin'\n",
    "\n",
    "pretrained_model = fasttext.load_model(pretrained_model_path)\n",
    "\n",
    "pretrained_embedding_size = pretrained_model.get_dimension()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Word2Vec model on corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stocks making the biggest moves before the bel...</td>\n",
       "      <td>https://www.cnbc.com/2023/03/28/stocks-making-...</td>\n",
       "      <td>chinese technology stocks such as alibaba and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Be very vigilant': Bank of England chief says...</td>\n",
       "      <td>https://www.cnbc.com/2023/03/28/bank-of-englan...</td>\n",
       "      <td>andrew bailey, governor of the bank of england...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is not another banking crisis, analysts s...</td>\n",
       "      <td>https://www.cnbc.com/2023/03/28/this-is-not-an...</td>\n",
       "      <td>the collapse of u.s.-based silicon valley bank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private equity deals in Asia plunged 44% in 20...</td>\n",
       "      <td>https://www.cnbc.com/2023/03/28/private-equity...</td>\n",
       "      <td>asia-pacific's private equity market plummeted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stocks making the biggest midday moves: Coinba...</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/stocks-making-...</td>\n",
       "      <td>check out the companies making the biggest mov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   \n",
       "0  Stocks making the biggest moves before the bel...  \\\n",
       "1  'Be very vigilant': Bank of England chief says...   \n",
       "2  This is not another banking crisis, analysts s...   \n",
       "3  Private equity deals in Asia plunged 44% in 20...   \n",
       "4  Stocks making the biggest midday moves: Coinba...   \n",
       "\n",
       "                                                 URL   \n",
       "0  https://www.cnbc.com/2023/03/28/stocks-making-...  \\\n",
       "1  https://www.cnbc.com/2023/03/28/bank-of-englan...   \n",
       "2  https://www.cnbc.com/2023/03/28/this-is-not-an...   \n",
       "3  https://www.cnbc.com/2023/03/28/private-equity...   \n",
       "4  https://www.cnbc.com/2023/03/27/stocks-making-...   \n",
       "\n",
       "                                             Content  \n",
       "0  chinese technology stocks such as alibaba and ...  \n",
       "1  andrew bailey, governor of the bank of england...  \n",
       "2  the collapse of u.s.-based silicon valley bank...  \n",
       "3  asia-pacific's private equity market plummeted...  \n",
       "4  check out the companies making the biggest mov...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv(\"corpus.csv\", sep='@', index_col=0)\n",
    "corpus = corpus.loc[corpus['Content'] != '']\n",
    "corpus.dropna(subset=['Content'], axis=0, inplace=True)\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding training data in the corpus\n",
    "training_data = read_data(\"FinancialPhraseBank/Sentences_50Agree.txt\")\n",
    "training_data['News'] = training_data['News'].str.lower()\n",
    "training_data['News'] = training_data['News'].str.replace('\\n', '')\n",
    "training_data.dropna(subset=['News'], axis=0, inplace=True)\n",
    "training_data = training_data.loc[training_data['News'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = [word_tokenize(row[0]) for _, row in corpus.iterrows()] + [word_tokenize(row[-1]) for _, row in corpus.iterrows()] + [word_tokenize(row[0]) for _, row in training_data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_content = [word_tokenize(row[0]) for _, row in training_data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(sentence) for sentence in training_content]) # Max headline token length, going to need to pad according to this number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(sentences=content, vector_size=trained_embedding_size, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('increased.some', 0.9761280417442322),\n",
       " ('increase.as', 0.9685688018798828),\n",
       " ('increased', 0.9491811394691467),\n",
       " ('incredibly', 0.9409798979759216),\n",
       " ('increases', 0.9407033920288086),\n",
       " ('grease', 0.9346209168434143),\n",
       " ('outcomes.increased', 0.9345734715461731),\n",
       " ('revenue.', 0.9249630570411682),\n",
       " ('revenue', 0.9235275983810425),\n",
       " ('ratify', 0.9174684286117554)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = model.wv.most_similar('increase', topn=10)\n",
    "sims"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Train/Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing embedding model\n",
    "#embedding_model, embedding_size = model.wv, trained_embedding_size\n",
    "embedding_model, embedding_size = pretrained_model, pretrained_embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_data(\"FinancialPhraseBank/Sentences_50Agree.txt\")\n",
    "sentiment_dataset = NewsDataset(dataset, embedding_model, embedding_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>according to gran , the company has no plans t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>technopolis plans to develop in stages an area...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the international electronic industry company ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with the new production plant the company woul...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>according to the company 's updated strategy f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>london marketwatch -- share prices ended lower...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>operating profit fell to eur 35.4 mn from eur ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>net sales of the paper segment decreased to eu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>sales in finland decreased by 10.5 % in januar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4846 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   News  Sentiment\n",
       "0     according to gran , the company has no plans t...          1\n",
       "1     technopolis plans to develop in stages an area...          1\n",
       "2     the international electronic industry company ...          0\n",
       "3     with the new production plant the company woul...          2\n",
       "4     according to the company 's updated strategy f...          2\n",
       "...                                                 ...        ...\n",
       "4841  london marketwatch -- share prices ended lower...          0\n",
       "4842  rinkuskiai 's beer sales fell by 6.5 per cent ...          1\n",
       "4843  operating profit fell to eur 35.4 mn from eur ...          0\n",
       "4844  net sales of the paper segment decreased to eu...          0\n",
       "4845  sales in finland decreased by 10.5 % in januar...          0\n",
       "\n",
       "[4846 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.12382075471698113, 0.5958136792452831, 0.2803655660377358]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(sentiment_dataset, [round(0.7*len(sentiment_dataset)), round(0.3*len(sentiment_dataset))])\n",
    "label_distribution = (dataset.loc[train_set.indices, 'Sentiment'].value_counts() / dataset.loc[train_set.indices, 'Sentiment'].shape[0]).sort_index().to_list()\n",
    "label_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weights = [1 / w for w in label_distribution]\n",
    "class_weights = [2.5, 0.4, 1.3]\n",
    "weights = [class_weights[torch.argmax(label)] for _, label in train_set]\n",
    "train_sampler = WeightedRandomSampler(weights=weights, num_samples=len(train_set), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sentiment\n",
       " 1    0.595814\n",
       " 2    0.280366\n",
       " 0    0.123821\n",
       " Name: count, dtype: float64,\n",
       " Sentiment\n",
       " 1    0.590096\n",
       " 2    0.283356\n",
       " 0    0.126547\n",
       " Name: count, dtype: float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[train_set.indices, 'Sentiment'].value_counts() / dataset.loc[train_set.indices, 'Sentiment'].shape[0], dataset.loc[val_set.indices, 'Sentiment'].value_counts() / dataset.loc[val_set.indices, 'Sentiment'].shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = embedding_size\n",
    "batch_size = 64\n",
    "num_layers = 1\n",
    "hidden_size = 500\n",
    "lstm_model = LSTMModel(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 -- [3392/3392 (100.0%)]\tLoss: 0.6033651705058116\tAccuracy: 0.443\tTime taken: 2.625\tValidation Loss: 0.6576251983642578 || Validation Accuracy: 0.347\n",
      "Epoch: 2/30 -- [3392/3392 (100.0%)]\tLoss: 0.6002245905264368\tAccuracy: 0.453\tTime taken: 2.578125\tValidation Loss: 0.6581254005432129 || Validation Accuracy: 0.362\n",
      "Epoch: 3/30 -- [3392/3392 (100.0%)]\tLoss: 0.6042841301774079\tAccuracy: 0.433\tTime taken: 2.53125\tValidation Loss: 0.6627715229988098 || Validation Accuracy: 0.388\n",
      "Epoch: 4/30 -- [3392/3392 (100.0%)]\tLoss: 0.6120803311186017\tAccuracy: 0.431\tTime taken: 2.515625\tValidation Loss: 0.6302682161331177 || Validation Accuracy: 0.370\n",
      "Epoch: 5/30 -- [3392/3392 (100.0%)]\tLoss: 0.6015701496376181\tAccuracy: 0.448\tTime taken: 2.46875\tValidation Loss: 0.6469096541404724 || Validation Accuracy: 0.395\n",
      "Epoch: 6/30 -- [3392/3392 (100.0%)]\tLoss: 0.6004271597232459\tAccuracy: 0.451\tTime taken: 2.5\tValidation Loss: 0.6353815197944641 || Validation Accuracy: 0.394\n",
      "Epoch: 7/30 -- [3392/3392 (100.0%)]\tLoss: 0.595699242825778\tAccuracy: 0.463\tTime taken: 2.5\tValidation Loss: 0.6409493088722229 || Validation Accuracy: 0.364\n",
      "Epoch: 8/30 -- [3392/3392 (100.0%)]\tLoss: 0.5993701433235744\tAccuracy: 0.442\tTime taken: 2.5\tValidation Loss: 0.6171313524246216 || Validation Accuracy: 0.420\n",
      "Epoch: 9/30 -- [3392/3392 (100.0%)]\tLoss: 0.5914941666261205\tAccuracy: 0.466\tTime taken: 2.5\tValidation Loss: 0.6796467900276184 || Validation Accuracy: 0.298\n",
      "Epoch: 10/30 -- [3392/3392 (100.0%)]\tLoss: 0.5969755447135782\tAccuracy: 0.455\tTime taken: 2.5\tValidation Loss: 0.6576992273330688 || Validation Accuracy: 0.365\n",
      "Epoch: 11/30 -- [3392/3392 (100.0%)]\tLoss: 0.5973543243588142\tAccuracy: 0.448\tTime taken: 2.484375\tValidation Loss: 0.6345006823539734 || Validation Accuracy: 0.385\n",
      "Epoch: 12/30 -- [3392/3392 (100.0%)]\tLoss: 0.5956359651853453\tAccuracy: 0.456\tTime taken: 2.484375\tValidation Loss: 0.6658148765563965 || Validation Accuracy: 0.373\n",
      "Epoch: 13/30 -- [3392/3392 (100.0%)]\tLoss: 0.5896597853246724\tAccuracy: 0.468\tTime taken: 2.5\tValidation Loss: 0.6295214295387268 || Validation Accuracy: 0.439\n",
      "Epoch: 14/30 -- [3392/3392 (100.0%)]\tLoss: 0.5880235298624579\tAccuracy: 0.482\tTime taken: 2.515625\tValidation Loss: 0.6562222838401794 || Validation Accuracy: 0.374\n",
      "Epoch: 15/30 -- [3392/3392 (100.0%)]\tLoss: 0.5908363573956039\tAccuracy: 0.479\tTime taken: 2.484375\tValidation Loss: 0.6351004838943481 || Validation Accuracy: 0.420\n",
      "Epoch: 16/30 -- [3392/3392 (100.0%)]\tLoss: 0.5984627559499921\tAccuracy: 0.458\tTime taken: 2.5\tValidation Loss: 0.6400876641273499 || Validation Accuracy: 0.376\n",
      "Epoch: 17/30 -- [3392/3392 (100.0%)]\tLoss: 0.5955156335290873\tAccuracy: 0.463\tTime taken: 2.5\tValidation Loss: 0.6493335366249084 || Validation Accuracy: 0.366\n",
      "Epoch: 18/30 -- [3392/3392 (100.0%)]\tLoss: 0.5851468646301413\tAccuracy: 0.489\tTime taken: 2.5\tValidation Loss: 0.6621102690696716 || Validation Accuracy: 0.375\n",
      "Epoch: 19/30 -- [3392/3392 (100.0%)]\tLoss: 0.5959091355215829\tAccuracy: 0.473\tTime taken: 2.5\tValidation Loss: 0.6382339596748352 || Validation Accuracy: 0.398\n",
      "Epoch: 20/30 -- [3392/3392 (100.0%)]\tLoss: 0.5803304685736602\tAccuracy: 0.475\tTime taken: 2.5\tValidation Loss: 0.6451911926269531 || Validation Accuracy: 0.413\n",
      "Epoch: 21/30 -- [3392/3392 (100.0%)]\tLoss: 0.5778521749208558\tAccuracy: 0.503\tTime taken: 2.5\tValidation Loss: 0.648159384727478 || Validation Accuracy: 0.396\n",
      "Epoch: 22/30 -- [3392/3392 (100.0%)]\tLoss: 0.58232200820491\tAccuracy: 0.504\tTime taken: 2.5\tValidation Loss: 0.6352439522743225 || Validation Accuracy: 0.415\n",
      "Epoch: 23/30 -- [3392/3392 (100.0%)]\tLoss: 0.5731808655666855\tAccuracy: 0.502\tTime taken: 2.515625\tValidation Loss: 0.685117244720459 || Validation Accuracy: 0.318\n",
      "Epoch: 24/30 -- [3392/3392 (100.0%)]\tLoss: 0.5789588127496108\tAccuracy: 0.510\tTime taken: 2.5\tValidation Loss: 0.6278772354125977 || Validation Accuracy: 0.416\n",
      "Epoch: 25/30 -- [3392/3392 (100.0%)]\tLoss: 0.579621987522773\tAccuracy: 0.486\tTime taken: 2.5\tValidation Loss: 0.6567785143852234 || Validation Accuracy: 0.351\n",
      "Epoch: 26/30 -- [3392/3392 (100.0%)]\tLoss: 0.5735313082641026\tAccuracy: 0.509\tTime taken: 2.546875\tValidation Loss: 0.6807308793067932 || Validation Accuracy: 0.321\n",
      "Epoch: 27/30 -- [3392/3392 (100.0%)]\tLoss: 0.5851405476624111\tAccuracy: 0.492\tTime taken: 2.59375\tValidation Loss: 0.6639391779899597 || Validation Accuracy: 0.364\n",
      "Epoch: 28/30 -- [3392/3392 (100.0%)]\tLoss: 0.5870079769278472\tAccuracy: 0.484\tTime taken: 2.59375\tValidation Loss: 0.689637303352356 || Validation Accuracy: 0.309\n",
      "Epoch: 29/30 -- [3392/3392 (100.0%)]\tLoss: 0.5752580728171006\tAccuracy: 0.513\tTime taken: 2.578125\tValidation Loss: 0.6684166789054871 || Validation Accuracy: 0.329\n",
      "Epoch: 30/30 -- [3392/3392 (100.0%)]\tLoss: 0.574985830289013\tAccuracy: 0.518\tTime taken: 2.578125\tValidation Loss: 0.6647944450378418 || Validation Accuracy: 0.345\n",
      "Best accuracy : 0.43878954607977994 || Best confusion matrix : \n",
      " [[ 78.  25.  81.]\n",
      " [167. 361. 330.]\n",
      " [119.  94. 199.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6033651705058116,\n",
       "  0.6002245905264368,\n",
       "  0.6042841301774079,\n",
       "  0.6120803311186017,\n",
       "  0.6015701496376181,\n",
       "  0.6004271597232459,\n",
       "  0.595699242825778,\n",
       "  0.5993701433235744,\n",
       "  0.5914941666261205,\n",
       "  0.5969755447135782,\n",
       "  0.5973543243588142,\n",
       "  0.5956359651853453,\n",
       "  0.5896597853246724,\n",
       "  0.5880235298624579,\n",
       "  0.5908363573956039,\n",
       "  0.5984627559499921,\n",
       "  0.5955156335290873,\n",
       "  0.5851468646301413,\n",
       "  0.5959091355215829,\n",
       "  0.5803304685736602,\n",
       "  0.5778521749208558,\n",
       "  0.58232200820491,\n",
       "  0.5731808655666855,\n",
       "  0.5789588127496108,\n",
       "  0.579621987522773,\n",
       "  0.5735313082641026,\n",
       "  0.5851405476624111,\n",
       "  0.5870079769278472,\n",
       "  0.5752580728171006,\n",
       "  0.574985830289013],\n",
       " [0.44339622641509435,\n",
       "  0.4525353773584906,\n",
       "  0.43307783018867924,\n",
       "  0.43101415094339623,\n",
       "  0.44752358490566035,\n",
       "  0.4513561320754717,\n",
       "  0.46285377358490565,\n",
       "  0.44192216981132076,\n",
       "  0.46639150943396224,\n",
       "  0.4548938679245283,\n",
       "  0.4481132075471698,\n",
       "  0.4563679245283019,\n",
       "  0.4684551886792453,\n",
       "  0.48172169811320753,\n",
       "  0.47877358490566035,\n",
       "  0.45784198113207547,\n",
       "  0.46255896226415094,\n",
       "  0.48850235849056606,\n",
       "  0.47317216981132076,\n",
       "  0.47464622641509435,\n",
       "  0.5029481132075472,\n",
       "  0.5038325471698113,\n",
       "  0.5020636792452831,\n",
       "  0.5097287735849056,\n",
       "  0.4861438679245283,\n",
       "  0.5088443396226415,\n",
       "  0.49174528301886794,\n",
       "  0.484375,\n",
       "  0.5126768867924528,\n",
       "  0.5179834905660378],\n",
       " [tensor(0.6576, device='cuda:0'),\n",
       "  tensor(0.6581, device='cuda:0'),\n",
       "  tensor(0.6628, device='cuda:0'),\n",
       "  tensor(0.6303, device='cuda:0'),\n",
       "  tensor(0.6469, device='cuda:0'),\n",
       "  tensor(0.6354, device='cuda:0'),\n",
       "  tensor(0.6409, device='cuda:0'),\n",
       "  tensor(0.6171, device='cuda:0'),\n",
       "  tensor(0.6796, device='cuda:0'),\n",
       "  tensor(0.6577, device='cuda:0'),\n",
       "  tensor(0.6345, device='cuda:0'),\n",
       "  tensor(0.6658, device='cuda:0'),\n",
       "  tensor(0.6295, device='cuda:0'),\n",
       "  tensor(0.6562, device='cuda:0'),\n",
       "  tensor(0.6351, device='cuda:0'),\n",
       "  tensor(0.6401, device='cuda:0'),\n",
       "  tensor(0.6493, device='cuda:0'),\n",
       "  tensor(0.6621, device='cuda:0'),\n",
       "  tensor(0.6382, device='cuda:0'),\n",
       "  tensor(0.6452, device='cuda:0'),\n",
       "  tensor(0.6482, device='cuda:0'),\n",
       "  tensor(0.6352, device='cuda:0'),\n",
       "  tensor(0.6851, device='cuda:0'),\n",
       "  tensor(0.6279, device='cuda:0'),\n",
       "  tensor(0.6568, device='cuda:0'),\n",
       "  tensor(0.6807, device='cuda:0'),\n",
       "  tensor(0.6639, device='cuda:0'),\n",
       "  tensor(0.6896, device='cuda:0'),\n",
       "  tensor(0.6684, device='cuda:0'),\n",
       "  tensor(0.6648, device='cuda:0')],\n",
       " [0.34731774415405775,\n",
       "  0.3624484181568088,\n",
       "  0.3878954607977992,\n",
       "  0.3700137551581843,\n",
       "  0.3954607977991747,\n",
       "  0.3940852819807428,\n",
       "  0.3638239339752407,\n",
       "  0.4195323246217332,\n",
       "  0.2977991746905089,\n",
       "  0.36451169188445665,\n",
       "  0.38514442916093533,\n",
       "  0.3734525447042641,\n",
       "  0.43878954607977994,\n",
       "  0.3741403026134801,\n",
       "  0.4202200825309491,\n",
       "  0.37551581843191195,\n",
       "  0.3658872077028886,\n",
       "  0.374828060522696,\n",
       "  0.39752407152682256,\n",
       "  0.4126547455295736,\n",
       "  0.39614855570839064,\n",
       "  0.4154057771664374,\n",
       "  0.3177441540577717,\n",
       "  0.4160935350756534,\n",
       "  0.35075653370013754,\n",
       "  0.32118294360385147,\n",
       "  0.3638239339752407,\n",
       "  0.30880330123796423,\n",
       "  0.3294360385144429,\n",
       "  0.3452544704264099],\n",
       " array([[ 78.,  25.,  81.],\n",
       "        [167., 361., 330.],\n",
       "        [119.,  94., 199.]]),\n",
       " 0.43878954607977994)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lstm(lstm_model, train_set, val_set, 30, 0.0001, batch_size, num_layers, hidden_size, device, train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airbus', 'won', 'case']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2697, 0.3758, 0.3545], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'Airbus won case'\n",
    "test = test.lower()\n",
    "test = word_tokenize(test)\n",
    "n = len(test)\n",
    "print(test)\n",
    "try:\n",
    "    test = [embedding_model[token] for token in test]\n",
    "except:\n",
    "    test = [embedding_model.get_word_vector(token) for token in test]\n",
    "test = torch.Tensor(test).to(device)\n",
    "test = F.pad(test, (0, 0, max_length - n, 0), 'constant', 0)\n",
    "hidden = (torch.zeros(num_layers, hidden_size).to(device), torch.zeros(\n",
    "                num_layers, hidden_size).to(device))\n",
    "lstm_model(test, hidden)[0][-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e7f7ece2f4c3e30cc6971059714188e0a0cc944cd6cc9496d585856c2732f0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
